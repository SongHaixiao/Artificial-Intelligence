# Backpropagating Errors with Matrix Multiplication

[toc]

## Vectorise the Process

Being able to express a lot of calculations in matrix form makes it more concise for us to write down, and also allows computers to do all that work much more efficiently because they take advantage of the repetitive similarities in the calculations that need to be done. 



## Transposing a Martix

- transposing a matrix

- written : $w^T$
  $$
  \begin{pmatrix}
  & 1 & 2 & 3 & \\
  & 4 & 5 & 6 & \\ 
  & 7 & 8 & 9 & \\
  \end{pmatrix} ^T
  
  = \begin{pmatrix}
  & 1 & 4 & 7 & \\
  & 2 & 5 & 8 & \\ 
  & 3 & 6 & 9 & \\
  \end{pmatrix} 
  $$

  $$
  \begin{pmatrix}
  & 1 & 2 & 3 & \\
  & 4 & 5 & 6 & \\
  \end{pmatrix} ^T
  
  = \begin{pmatrix}
  & 1 & 4 & \\
  & 2 & 5 & \\
  & 3 & 6 & \\
  \end{pmatrix} 
  $$

  

## Errors in the Output Layer

Here we only have two nodes in the output layer, so these $e_1$ and $e_2$.
$$
error_{output} =
\begin{pmatrix}
& e_1 & \\
& e_2 & \\
\end{pmatrix}
$$

## Errors in the Hidden Layer Errors

The errors for the hidden layer:
$$
error_{hiddden} =
\begin{pmatrix}
& (e_1*w_{11}) + (e_2 * w_{12}) & \\
& (e_1*w_{21}) + (e_2 * w_{22}) & \\
\end{pmatrix}
$$
Spot the matrix multiplication :
$$
error_{hidden} = 
\begin{pmatrix}
& w_{11} & w_{12} &  \\
& w_{21} & w_{22} & \\
\end{pmatrix}

\cdot

\begin{pmatrix}
& e_1 & \\
& e_2 & \\
\end{pmatrix}
$$
That weight matrix is like the one we constructed before but has been flipped along a diagonal line so that the top right is now at the bottom left, and the bottom left is at the top right.

So the errors back:
$$
error_{hidden} = W^T_{hidden\_output} \cdot error_{output}
$$

## Key Points

- Backpropagating the error can be expressed as a matrix multiplication.
- This allows us to express it concisely, irrespective of network size, and also allows computer languages that understand matrix calculations to do the work more efficiently and quickly. 

- This means **both** feeding signals forward and error backpropagation can be made efficient using matrix calculations.